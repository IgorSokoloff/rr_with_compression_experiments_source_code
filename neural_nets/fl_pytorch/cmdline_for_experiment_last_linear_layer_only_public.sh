# Command line for experiment with job_id=QSGD ($\gamma=$0.0006)
python run.py --global-lr "0.0006" --local-lr "1" --run-id "qsgd_0.0006_18836" --logfile "../logs/qsgd_0.0006.txt" --out "qsgd_0.0006.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "694063ca80a8f491d729ddd4674dcd82e3fdf9c9" --wandb-project-name "scripts_no_bn_last_layer_with_imgnet_w_final_with_l2norm_regul" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.0006).bin"

# Command line for experiment with job_id=QSGD(gamma=0.003)
python run.py --global-lr "0.003" --local-lr "1" --run-id "qsgd_0.003_980" --logfile "../logs/qsgd_0.003.txt" --out "qsgd_0.003.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.003).bin"

# Command line for experiment with job_id=QSGD(gamma=0.001)
python run.py --global-lr "0.001" --local-lr "1" --run-id "qsgd_0.001_30107" --logfile "../logs/qsgd_0.001.txt" --out "qsgd_0.001.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.001).bin"

# Command line for experiment with job_id=QSGD(gamma=0.01)
python run.py --global-lr "0.01" --local-lr "1" --run-id "qsgd_0.01_17673" --logfile "../logs/qsgd_0.01.txt" --out "qsgd_0.01.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.01).bin"

# Command line for experiment with job_id=QSGD(gamma=0.03)
python run.py --global-lr "0.03" --local-lr "1" --run-id "qsgd_0.03_673" --logfile "../logs/qsgd_0.03.txt" --out "qsgd_0.03.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.03).bin"

# Command line for experiment with job_id=QSGD(gamma=0.06)
python run.py --global-lr "0.06" --local-lr "1" --run-id "qsgd_0.06_6032" --logfile "../logs/qsgd_0.06.txt" --out "qsgd_0.06.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.06).bin"

# Command line for experiment with job_id=QSGD(gamma=0.5)
python run.py --global-lr "0.5" --local-lr "1" --run-id "qsgd_0.5_28372" --logfile "../logs/qsgd_0.5.txt" --out "qsgd_0.5.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.5).bin"

# Command line for experiment with job_id=QSGD(gamma=0.1)
python run.py --global-lr "0.1" --local-lr "1" --run-id "qsgd_0.1_3687" --logfile "../logs/qsgd_0.1.txt" --out "qsgd_0.1.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.1).bin"

# Command line for experiment with job_id=QSGD(gamma=0.2)
python run.py --global-lr "0.2" --local-lr "1" --run-id "qsgd_0.2_5020" --logfile "../logs/qsgd_0.2.txt" --out "qsgd_0.2.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.2).bin"

# Command line for experiment with job_id=QSGD(gamma=0.25)
python run.py --global-lr "0.25" --local-lr "1" --run-id "qsgd_0.25_8643" --logfile "../logs/qsgd_0.25.txt" --out "qsgd_0.25.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.25).bin"

# Command line for experiment with job_id=QSGD(gamma=0.75)
python run.py --global-lr "0.75" --local-lr "1" --run-id "qsgd_0.75_2060" --logfile "../logs/qsgd_0.75.txt" --out "qsgd_0.75.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=0.75).bin"

# Command line for experiment with job_id=QSGD(gamma=1.0)
python run.py --global-lr "1.0" --local-lr "1" --run-id "qsgd_1.0_4521" --logfile "../logs/qsgd_1.0.txt" --out "qsgd_1.0.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=1.0).bin"

# Command line for experiment with job_id=QSGD(gamma=1.25)
python run.py --global-lr "1.25" --local-lr "1" --run-id "qsgd_1.25_8880" --logfile "../logs/qsgd_1.25.txt" --out "qsgd_1.25.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=1.25).bin"

# Command line for experiment with job_id=QSGD(gamma=2.00)
python run.py --global-lr "2.00" --local-lr "1" --run-id "qsgd_2.00_20337" --logfile "../logs/qsgd_2.00.txt" --out "qsgd_2.00.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=2.00).bin"

# Command line for experiment with job_id=QSGD(gamma=2.5)
python run.py --global-lr "2.5" --local-lr "1" --run-id "qsgd_2.5_15397" --logfile "../logs/qsgd_2.5.txt" --out "qsgd_2.5.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=2.5).bin"

# Command line for experiment with job_id=QSGD(gamma=3.00)
python run.py --global-lr "3.00" --local-lr "1" --run-id "qsgd_3.00_31328" --logfile "../logs/qsgd_3.00.txt" --out "qsgd_3.00.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=3.00).bin"

# Command line for experiment with job_id=QSGD(gamma=3.75)
python run.py --global-lr "3.75" --local-lr "1" --run-id "qsgd_3.75_15131" --logfile "../logs/qsgd_3.75.txt" --out "qsgd_3.75.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=3.75).bin"

# Command line for experiment with job_id=QSGD(gamma=4.00)
python run.py --global-lr "4.00" --local-lr "1" --run-id "qsgd_4.00_14215" --logfile "../logs/qsgd_4.00.txt" --out "qsgd_4.00.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "1" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:sgd-multi,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD(gamma=4.00).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.001)
python run.py --global-lr "0.001" --run-id "qsgd_rr_0.001_22572" --logfile "../logs/qsgd_rr_0.001.txt" --out "rr_qsgd_0.001.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.001).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.01)
python run.py --global-lr "0.01" --run-id "qsgd_rr_0.01_18098" --logfile "../logs/qsgd_rr_0.01.txt" --out "rr_qsgd_0.01.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.01).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.03)
python run.py --global-lr "0.03" --run-id "qsgd_rr_0.03_25674" --logfile "../logs/qsgd_rr_0.03.txt" --out "rr_qsgd_0.03.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.03).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.06)
python run.py --global-lr "0.06" --run-id "qsgd_rr_0.06_14914" --logfile "../logs/qsgd_rr_0.06.txt" --out "rr_qsgd_0.06.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.06).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.1)
python run.py --global-lr "0.1" --run-id "qsgd_rr_0.1_24258" --logfile "../logs/qsgd_rr_0.1.txt" --out "rr_qsgd_0.1.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.1).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.2)
python run.py --global-lr "0.2" --run-id "qsgd_rr_0.2_22344" --logfile "../logs/qsgd_rr_0.2.txt" --out "rr_qsgd_0.2.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.2).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.25)
python run.py --global-lr "0.25" --run-id "qsgd_rr_0.25_31626" --logfile "../logs/qsgd_rr_0.25.txt" --out "rr_qsgd_0.25.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.25).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.75)
python run.py --global-lr "0.75" --run-id "qsgd_rr_0.75_7338" --logfile "../logs/qsgd_rr_0.75.txt" --out "rr_qsgd_0.75.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.75).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=1.0)
python run.py --global-lr "1.0" --run-id "qsgd_rr_1.0_31177" --logfile "../logs/qsgd_rr_1.0.txt" --out "rr_qsgd_1.0.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=1.0).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=1.25)
python run.py --global-lr "1.25" --run-id "qsgd_rr_1.25_30420" --logfile "../logs/qsgd_rr_1.25.txt" --out "rr_qsgd_1.25.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=1.25).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=2.00)
python run.py --global-lr "2.00" --run-id "qsgd_rr_2.00_21290" --logfile "../logs/qsgd_rr_2.00.txt" --out "rr_qsgd_2.00.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=2.00).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=2.5)
python run.py --global-lr "2.5" --run-id "qsgd_rr_2.5_23590" --logfile "../logs/qsgd_rr_2.5.txt" --out "rr_qsgd_2.5.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=2.5).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=3.00)
python run.py --global-lr "3.00" --run-id "qsgd_rr_3.00_31566" --logfile "../logs/qsgd_rr_3.00.txt" --out "rr_qsgd_3.00.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=3.00).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=3.75)
python run.py --global-lr "3.75" --run-id "qsgd_rr_3.75_14606" --logfile "../logs/qsgd_rr_3.75.txt" --out "rr_qsgd_3.75.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=3.75).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=4.00)
python run.py --global-lr "4.00" --run-id "qsgd_rr_4.00_5734" --logfile "../logs/qsgd_rr_4.00.txt" --out "rr_qsgd_4.00.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=4.00).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.003)
python run.py --global-lr "0.003" --run-id "qsgd_rr_0.003_24863" --logfile "../logs/qsgd_rr_0.003.txt" --out "rr_qsgd_0.003.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.003).bin"

# Command line for experiment with job_id=QSGD-RR(gamma=0.0006)
python run.py --global-lr "0.0006" --run-id "qsgd_rr_0.0006_28043" --logfile "../logs/qsgd_rr_0.0006.txt" --out "rr_qsgd_0.0006.bin" --algorithm "dcgd" --rounds "10000" --gpu "0" --local-lr "1" --comment "" --client-sampling-type "uniform" --num-clients-per-round "10" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --run-local-steps --batch-size "600" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "cifar10_fl" --loss "crossentropy" --model "tv_resnet18" --per-round-clean-torch-cache --turn-off-batch-normalization-and-dropout --use-pretrained --train-last-layer --metric "top_1_acc" --global-regulizer "cvx_l2norm_square_div_2" --global-regulizer-alpha "0.0001" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --log-gpu-usage --num-workers-train "4" --num-workers-test "4" --deterministic --manual-init-seed "123" --manual-runtime-seed "2" --group-name "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "0" --algorithm-options "internal_sgd:iterated-minibatch,reshuffle:until_exhausted,tau:10%" --client-compressor "randk:5%" --extra-track "full_gradient_norm_train,full_objective_value_train,full_gradient_norm_val,full_objective_value_val" --allow-use-nv-tensorcores --initialize-shifts-policy "zero" --sort-dataset-by-class-before-split --wandb-key "xxxxxxxxxxx" --wandb-project-name "vvvvvvvvvv" --loglevel "debug" --logfilter ".*" --out "QSGD-RR(gamma=0.0006).bin"
